{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))  # Add parent dir to path\n",
    "from utils.chunker import Chunker\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader(\"Owners_Manual.pdf\")\n",
    "pages = loader.load()\n",
    "all_text = \" \".join([page.page_content for page in pages])\n",
    "chunker = Chunker()\n",
    "chunks = chunker.recursive(all_text)  # Choose one: .fixed_size, .nltk_sentence_chunks, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/n_s0gq250750gnpxmjk5l0qm0000gn/T/ipykernel_37068/3559009047.py:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedding_model = HuggingFaceEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "def embeddings(chunks):\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    embed_docs = model.encode([doc.page_content for doc in chunks])\n",
    "    return embed_docs\n",
    "print(embeddings(chunks))\n",
    "embedding_model = HuggingFaceEmbeddings()\n",
    "\n",
    "docs = [Document(page_content=chunk) for chunk in chunks]\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    openai_api_key=API_KEY\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = vectorstore.as_retriever()\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True  # Optional, helpful for debugging\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have specific details on Tesla's starting and powering off procedures from the provided context. However, generally, Tesla vehicles start and power off automatically based on the presence of the key fob or smartphone app. When you enter the vehicle with the key fob or your phone, the car powers on, and when you exit and walk away, it powers off. For precise instructions, it would be best to refer to the vehicle's owner's manual or Tesla's official resources.\n"
     ]
    }
   ],
   "source": [
    "# qa_chain.run(\"talk about Tesla's starting and powering off?\")\n",
    "\n",
    "response = qa_chain.invoke({\"query\": \"talk about Tesla's starting and powering off?\"})\n",
    "print(response[\"result\"])  # or print(response) to see full output including sources\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
